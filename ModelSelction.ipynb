{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.45      0.47      0.46       182\n",
      "        home       0.55      0.55      0.55       224\n",
      "        near       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.50       414\n",
      "   macro avg       0.34      0.34      0.34       414\n",
      "weighted avg       0.50      0.50      0.50       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       1.00      1.00      1.00       560\n",
      "        home       1.00      1.00      1.00       669\n",
      "        near       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00      1241\n",
      "   macro avg       1.00      1.00      1.00      1241\n",
      "weighted avg       1.00      1.00      1.00      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "pred = tree.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = tree.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest\n",
    "## default 파라미터 사용시 심한 과적합 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.45      0.45      0.45       175\n",
      "        home       0.59      0.60      0.59       234\n",
      "        near       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.53       414\n",
      "   macro avg       0.35      0.35      0.35       414\n",
      "weighted avg       0.52      0.53      0.53       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       1.00      0.99      1.00       567\n",
      "        home       1.00      1.00      1.00       659\n",
      "        near       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00      1241\n",
      "   macro avg       1.00      1.00      1.00      1241\n",
      "weighted avg       1.00      1.00      1.00      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion = 'gini', n_estimators=25)\n",
    "forest.fit(x_train, y_train)\n",
    "pred = forest.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = forest.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.61      0.31      0.41       204\n",
      "        home       0.52      0.81      0.63       201\n",
      "        near       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.54       414\n",
      "   macro avg       0.38      0.37      0.35       414\n",
      "weighted avg       0.55      0.54      0.51       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.57      0.33      0.42       538\n",
      "        home       0.60      0.81      0.69       692\n",
      "        near       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.60      1241\n",
      "   macro avg       0.39      0.38      0.37      1241\n",
      "weighted avg       0.58      0.60      0.57      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=100, max_iter=1000)\n",
    "lr.fit(x_train, y_train)\n",
    "pred = lr.predict(x_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = lr.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포트벡터머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.49      0.29      0.36       174\n",
      "        home       0.58      0.78      0.67       234\n",
      "        near       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.56       414\n",
      "   macro avg       0.36      0.36      0.34       414\n",
      "weighted avg       0.54      0.56      0.53       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.58      0.32      0.41       568\n",
      "        home       0.57      0.81      0.67       659\n",
      "        near       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.57      1241\n",
      "   macro avg       0.38      0.37      0.36      1241\n",
      "weighted avg       0.57      0.57      0.54      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=2, degree=5, gamma=0.001)\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = svm.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확률 경사 하강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.44      0.47      0.46       177\n",
      "        home       0.58      0.55      0.57       233\n",
      "        near       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51       414\n",
      "   macro avg       0.34      0.34      0.34       414\n",
      "weighted avg       0.52      0.51      0.51       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.48      0.47      0.47       565\n",
      "        home       0.55      0.57      0.56       660\n",
      "        near       0.12      0.06      0.08        16\n",
      "\n",
      "    accuracy                           0.52      1241\n",
      "   macro avg       0.39      0.37      0.37      1241\n",
      "weighted avg       0.51      0.52      0.52      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "gdlr = SGDClassifier(loss='log')\n",
    "gdlr.fit(x_train, y_train)\n",
    "pred = gdlr.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = gdlr.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.48      0.40      0.44       184\n",
      "        home       0.56      0.59      0.57       223\n",
      "        near       0.03      0.14      0.06         7\n",
      "\n",
      "    accuracy                           0.50       414\n",
      "   macro avg       0.36      0.38      0.35       414\n",
      "weighted avg       0.52      0.50      0.50       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.49      0.42      0.45       558\n",
      "        home       0.57      0.58      0.57       670\n",
      "        near       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.50      1241\n",
      "   macro avg       0.35      0.33      0.34      1241\n",
      "weighted avg       0.53      0.50      0.51      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "gdsv = SGDClassifier(loss='hinge')\n",
    "gdsv.fit(x_train, y_train)\n",
    "pred = gdsv.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = gdsv.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.52      0.43      0.47       199\n",
      "        home       0.53      0.62      0.57       209\n",
      "        near       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.52       414\n",
      "   macro avg       0.35      0.35      0.35       414\n",
      "weighted avg       0.52      0.52      0.51       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.47      0.43      0.45       543\n",
      "        home       0.58      0.61      0.60       684\n",
      "        near       0.12      0.21      0.15        14\n",
      "\n",
      "    accuracy                           0.53      1241\n",
      "   macro avg       0.39      0.42      0.40      1241\n",
      "weighted avg       0.53      0.53      0.53      1241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(alpha=0.001, max_iter=2000,eta0=0.1, tol=1e-3)\n",
    "ppn.fit(x_train, y_train)\n",
    "pred = ppn.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = ppn.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       1.00      0.01      0.01       186\n",
      "        home       0.54      1.00      0.70       221\n",
      "        near       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.54       414\n",
      "   macro avg       0.51      0.34      0.24       414\n",
      "weighted avg       0.73      0.54      0.38       414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        away       0.60      0.01      0.01       556\n",
      "        home       0.54      1.00      0.70       672\n",
      "        near       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.54      1241\n",
      "   macro avg       0.38      0.33      0.24      1241\n",
      "weighted avg       0.56      0.54      0.39      1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\103-04\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#승무패를 처리하는 result_fnc0, 승1패를 처리하는 result_fnc1\n",
    "from BaseballGameResult import result_fnc0, result_fnc1\n",
    "#1차 모델링 WAR정보가 없는 경우 0 \n",
    "import pandas as pd\n",
    "game_war = pd.read_csv('game_war.csv', encoding='cp949')\n",
    "\n",
    "game_score = pd.read_csv('game_score.csv', encoding = 'cp949', header=None)\n",
    "game_score.columns = ['경기', '결과']\n",
    "\n",
    "df = pd.merge(game_war, game_score , on='경기' )\n",
    "df['결과'] = df.결과.apply(lambda x: int(x.split(':')[0])-int(x.split(':')[1]) )\n",
    "#승1패\n",
    "#df['결과'] = df.결과.apply(result_fnc1)\n",
    "#승무패\n",
    "df['결과'] = df.결과.apply(result_fnc0)\n",
    "\n",
    "y = df.결과\n",
    "x = df.drop(['경기','결과', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=500, p=2, metric = 'minkowski') \n",
    "knn.fit(x_train, y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "\n",
    "#overfit\n",
    "pred_over_fit = knn.predict(x_train)\n",
    "report_over_fit = classification_report(y_train, pred_over_fit)\n",
    "\n",
    "print(report)\n",
    "print(report_over_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
